{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "N9zO8frwv9xk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5s6UDgnAwAuI"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "suicide_detection_df = pd.read_csv('Suicide_Detection.csv')\n",
        "ideation_df = pd.read_csv('Suicide_Ideation_Dataset(Twitter-based).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Owtiv03pwCMs"
      },
      "outputs": [],
      "source": [
        "# Handle missing values in the Ideation dataset\n",
        "ideation_df = ideation_df.dropna(subset=['Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "abykRW1lwFOQ"
      },
      "outputs": [],
      "source": [
        "# Convert categorical labels to numerical format\n",
        "label_encoder_sd = LabelEncoder()\n",
        "suicide_detection_df['class'] = label_encoder_sd.fit_transform(suicide_detection_df['class'])\n",
        "label_encoder_ideation = LabelEncoder()\n",
        "ideation_df['Semantic'] = label_encoder_ideation.fit_transform(ideation_df['Semantic'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tbXAk_-JwLV9"
      },
      "outputs": [],
      "source": [
        "# Combine the text data from both datasets\n",
        "combined_texts = pd.concat([suicide_detection_df['text'], ideation_df['Text']], axis=0)\n",
        "combined_labels = pd.concat([suicide_detection_df['class'], ideation_df['Semantic']], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "igov-Iq3wOqC"
      },
      "outputs": [],
      "source": [
        "# Tokenize and pad the sequences\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(combined_texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(combined_texts)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=100, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xwUXoGQHwRy4"
      },
      "outputs": [],
      "source": [
        "# Split the data back into respective datasets\n",
        "suicide_detection_sequences = padded_sequences[:len(suicide_detection_df)]\n",
        "ideation_sequences = padded_sequences[len(suicide_detection_df):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kGkulXAywTkH"
      },
      "outputs": [],
      "source": [
        "# Extract labels\n",
        "suicide_detection_labels = combined_labels[:len(suicide_detection_df)].values\n",
        "ideation_labels = combined_labels[len(suicide_detection_df):].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EhuJmxdqwVq0"
      },
      "outputs": [],
      "source": [
        "# Combine datasets (optional)\n",
        "all_sequences = np.concatenate([suicide_detection_sequences, ideation_sequences])\n",
        "all_labels = np.concatenate([suicide_detection_labels, ideation_labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-wPIyvp2wXur"
      },
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(all_sequences, all_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-umlTo7wZ9q",
        "outputId": "d63cd2cc-bbbd-4a41-8662-7be3db8e7a07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Build the model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=128, input_length=100),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(64),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "z5BKmtOXwdK9"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IjGlviHwfCn",
        "outputId": "9b160f65-5528-4b17-f817-fe5e9e8fcb70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 15ms/step - accuracy: 0.9722 - loss: 0.0763 - val_accuracy: 0.9379 - val_loss: 0.1890\n",
            "Epoch 2/5\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 15ms/step - accuracy: 0.9784 - loss: 0.0611 - val_accuracy: 0.9377 - val_loss: 0.1977\n",
            "Epoch 3/5\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 15ms/step - accuracy: 0.9833 - loss: 0.0482 - val_accuracy: 0.9379 - val_loss: 0.2313\n",
            "Epoch 4/5\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 15ms/step - accuracy: 0.9870 - loss: 0.0376 - val_accuracy: 0.9363 - val_loss: 0.2696\n",
            "Epoch 5/5\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 15ms/step - accuracy: 0.9900 - loss: 0.0293 - val_accuracy: 0.9343 - val_loss: 0.2448\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test), batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDN4Lf5Uw7Bv",
        "outputId": "0adfa47e-19fe-47fe-f750-94ada0956363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1462/1462\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkTdrj7SUUO4",
        "outputId": "029354a9-ee5e-48f6-f1e9-5ce8d18eb9df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 93.43%\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kovxpqxya8G0",
        "outputId": "91c70294-ea37-42dd-f81b-8caba884f6d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['suicide_detection_model.joblib']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'suicide_detection_model.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQWz14bE4dDs",
        "outputId": "2b77adc5-c2b2-4a05-f860-9aa4c1fcd5f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "88.784658908844\n",
            "The model predicts: Suicide\n"
          ]
        }
      ],
      "source": [
        "# Sample input text\n",
        "sample_text = [\"I feel like it's over\"]\n",
        "\n",
        "# Preprocess the input text (tokenization and padding)\n",
        "sample_sequence = tokenizer.texts_to_sequences(sample_text)\n",
        "sample_padded = pad_sequences(sample_sequence, maxlen=100, padding='post', truncating='post')\n",
        "\n",
        "# Predict the class using the trained model\n",
        "prediction = model.predict(sample_padded)\n",
        "predicted_class = (prediction > 0.5).astype(int)\n",
        "print(prediction[0][0]*100)\n",
        "# Decode the predicted class\n",
        "if predicted_class[0] == 0:\n",
        "    print(\"The model predicts: Non-Suicide\")\n",
        "else:\n",
        "    print(\"The model predicts: Suicide\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRSmrm1q67Qw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
